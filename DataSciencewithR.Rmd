---
title: "Data Science with R"
author: "JH"
date: "February 6, 2017"
output: html_document
---
Importing data:
file-based data: CSV, txt, excel
web-based data: XML, HTML JSON
database data: SQL, MySQL
Statistical data: SAS, SPSS, Stata

Cleaning data:
Reshape data
Rename columns
Convert data types
Ensure proper encoding
Ensure internal consistency
Handle errors and outliers
Handling missing values

Transforming data:
Select columns
Filter rows
Group rows
Order rows
Merge tables

plyr: splitting, applying and combining data within R
dplyr: data manipulation using data frames, data tables, and databases
data.table:
sqldf:

Exporting data:

```{r}
# Using dplyr:
# select
# filter
# mutate
# summarize
# arrange
# join, merge

library("dplyr")

cars <- read.table(
  file = "Cars.txt",
  header = TRUE,
  sep = "\t",
  quote = "\""
  )

head(cars)

# select three columns 
temp <- select(
  .data = cars,
  Transmission,
  Cylinders,
  Fuel.Economy)

# Inspect data
head(temp)

# Filter a subset of rows
temp <- filter(
  .data = temp,
  Transmission == "Automatic"
)

# Inspect data
head(temp)

# Compute a new column
temp <- mutate(
  .data = temp,
  Consumption = Fuel.Economy * 0.425
)

# Inspect data
head(temp)

# Group by a column
temp <- group_by(
  .data = temp,
  Cylinders
)

# Inspect data
head(temp)

# Aggregate based on groups
temp <- summarize(
  .data= temp,
  Avg.Consumption = mean(Consumption)
)

# Inspect data
head(temp)

# Arrange the rows in descending order
temp <- arrange(
  .data = temp,
  desc(Avg.Consumption)
)

# Inspect data
head(temp)

# Convert to data frame
efficiency <- as.data.frame(temp)

# Inspect the results
print(efficiency)

# Chain method together
efficiency <- cars %>%
  select(Fuel.Economy, Cylinders, Transmission) %>% 
  filter(Transmission == "Automatic") %>%
  mutate(Consumption = Fuel.Economy * 0.425) %>%
  group_by(Cylinders) %>%
  summarize(Avg.Consumption = mean(Consumption)) %>%
  arrange(desc(Avg.Consumption)) %>%
  as.data.frame()

# Inspect the results
print(efficiency)

# Save the results to a cvs file
write.csv(
  x = efficiency,
  file = "Fuel Efficiency.csv",
  row.names = FALSE
)
```

Discriptive Statistics
```{r}
# Create a frequency table
table(cars$Transmission)

# Get the minimum value
min(cars$Fuel.Economy)

# Get the maximun value
max(cars$Fuel.Economy)

# Get the average value
mean(cars$Fuel.Economy)

# Get the median value
median(cars$Fuel.Economy)

# Get the quartiles
quantile(cars$Fuel.Economy)

# Get the standard deviation
sd(cars$Fuel.Economy)

# Get the total value
sum(cars$Fuel.Economy)

# Get the correlation coefficient
cor(
  x = cars$Cylinders,
  y = cars$Fuel.Economy
)

# Summarize an entire table
summary(cars)
```

Visualizations

```{r}
# base graphics system
# lattice
# ggplot

library("ggplot2")

# create a frequency bar chart (categorical)
ggplot(
  data = cars,
  aes(x = Transmission)) +
  geom_bar() +             # what type of chart
  ggtitle("Count of Cars by Transmission Type") +
  xlab("transmission Type") + 
  ylab("Counts of Cars")

# Create a histogram (Numerical)
ggplot(
  data =cars,
  aes(x = Fuel.Economy)) + 
  geom_histogram(bins = 10) + 
  ggtitle("Distribution of Fuel Economy") +
  xlab("Fuel Economy (mpg)") + 
  ylab("Counts of Cars")  

# Create a density plot (Numerical)
ggplot(
  data =cars,
  aes(x = Fuel.Economy)) + 
  geom_density() + 
  ggtitle("Distribution of Fuel Economy") +
  xlab("Fuel Economy (mpg)") + 
  ylab("Density") 

# Create a scatter plot (Two numericals)
ggplot(
  data = cars,
  aes(x = Cylinders, y = Fuel.Economy)) +
  geom_point() +
  ggtitle("Fuel economy by Cylinders") +
  ylab("Fuel Economy (mpg)") + 
  xlab("Number of Cylinders")   
```

Handling big data

```{r}
# Load the ff package
library(ff)

# Read a csv file as ff data frame
irisff <- read.table.ffdf(
  file = "Iris.csv",
  FUN = "read.csv"
)

# Inspect the class
class(irisff)

# Inspect the column names
names(irisff)

# Load the biglm package
library(biglm)

# Create a linear regression model
model <- biglm(
  formula = Petal.Width ~ Petal.Length,
  data = irisff)

# Summarize the model
summary(model)

# Create a scatterplot
plot(
  x = irisff$Petal.Length[],
  y = irisff$Petal.Width[],
  main = "Iris Petal Length vs. Width",
  xlab = "Petal Length (cm)",
  ylab = "Petal Width (cm)"
)

# Get y-intercept from model
b <- summary(model)$mat[1,1]
b

# Get slope from model
m <- summary(model)$mat[2,1]

# Draw 
lines(
  x = irisff$Petal.Length[],
  y = m * irisff$Petal.Length[] + b,
  col = "red",
  lwd = 3
)

# Predict new values with model
predict(
  object = model,
  newdata = data.frame(
    Petal.Length = c(2,5,7),
    Petal.Width = c(0, 0, 0)
  )
)
```

Maching Learning
```{r}

# Load the data
data("iris")

# Set a seed
set.seed(42)

# Randomly sample 
indexes <- sample(
  x = 1:150,
  size = 100
)

# Inspect the random indexes
print(indexes)

# Create a training set from indexes
train <- iris[indexes, ]

# Create a test set
test <- iris[-indexes, ]

# Load the decision tree package
library(tree)

# Train a decision tree model
model <- tree(
  formula = Species ~ .,
  data = train
)

# Inspect the model 
summary(model)

# Visualize the decision tree model
plot(model)
text(model)

# Load color brewer library
library(RColorBrewer)

# Create a color palette
palette <- brewer.pal(3, "Set2")

# Create a scatterplot colored by species
plot(
  x = iris$Petal.Length,
  y = iris$Petal.Width,
  pch = 19,
  col = palette[as.numeric(iris$Species)],
  main = "Iris Petal Length vs. Width", 
  xlab = "Petal Length (cm)",
  ylab = "Petal Width (cm)"
)

# Plot the decision boundaries
partition.tree(
  tree = model,
  label = "Species",
  add = TRUE
)

# Predict with the model
predictions <- predict(
  object = model,
  newdata = test,
  type = "class"
)

# Create a confusion matrix
table(
  x = predictions,
  y = test$Species
)

# Load the caret package
library(caret)

# Evaluate the prediction results
confusionMatrix(
  data = predictions,
  reference = test$Species
)

# Save the tree model
save(model, file = "Tree.RData")
```
















